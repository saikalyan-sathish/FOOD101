{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uU80uVuOsIzg",
    "outputId": "da59c439-5098-436f-b7d3-817498132693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook last run (end-to-end): 2024-03-01 22:24:22.412444\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3Vy84Q_vkt6",
    "outputId": "366617f3-5db8-463f-8256-da8b2287f675"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 22:24:12.348363: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-01 22:24:12.348467: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-01 22:24:12.394773: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-01 22:24:12.483651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-01 22:24:13.614748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 22:24:14.959395: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:24:15.354557: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:24:15.355170: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:24:15.444521: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:24:15.444691: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:24:15.444800: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:24:15.444879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 2435 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU device found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZW9RHx0QsNkj",
    "outputId": "97a50527-5e89-477f-af3f-a973e5fdaf6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-01 22:24:28--  https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2404:6800:4009:804::201b, 2404:6800:4009:806::201b, 2404:6800:4009:832::201b, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4009:804::201b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 109540975 (104M) [application/zip]\n",
      "Saving to: ‘pizza_steak.zip’\n",
      "\n",
      "pizza_steak.zip     100%[===================>] 104.47M  10.6MB/s    in 11s     \n",
      "\n",
      "2024-03-01 22:24:40 (9.46 MB/s) - ‘pizza_steak.zip’ saved [109540975/109540975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8mpmA6a3ANiu"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pizza_steak.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m zip_ref \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpizza_steak.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m zip_ref\u001b[38;5;241m.\u001b[39mextractall()\n\u001b[1;32m      3\u001b[0m zip_ref\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pizza_steak.zip'"
     ]
    }
   ],
   "source": [
    "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlBE1ZrACmky"
   },
   "source": [
    "we start with a smaller dataset instead of the food101 because we can experiment quickly and figure what works before scalling up. The smaller dataset consists of only the pizza and steak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXQNbiJQDSXG"
   },
   "source": [
    "Now lets inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7ZXgHoiBtA8",
    "outputId": "87f3ee7f-dbbf-43da-bc20-7cc9d8dc2805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'pizza_steak': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls pizza_steak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q18UiYqQDk7b",
    "outputId": "4cb7a1cc-b829-445b-98bc-1dcd6615bee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza  steak\r\n"
     ]
    }
   ],
   "source": [
    "!ls pizza_steak/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n959FHwHD7UD",
    "outputId": "a8bc8273-02b8-463e-89b9-bc3d5a7cd479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000205.jpg  1647351.jpg  2238681.jpg  2824680.jpg  3375959.jpg  417368.jpg\r\n",
      "100135.jpg   1650002.jpg  2238802.jpg  2825100.jpg  3381560.jpg  4176.jpg\r\n",
      "101312.jpg   165639.jpg   2254705.jpg  2826987.jpg  3382936.jpg  42125.jpg\r\n",
      "1021458.jpg  1658186.jpg  225990.jpg   2832499.jpg  3386119.jpg  421476.jpg\r\n",
      "1032846.jpg  1658443.jpg  2260231.jpg  2832960.jpg  3388717.jpg  421561.jpg\r\n",
      "10380.jpg    165964.jpg   2268692.jpg  285045.jpg   3389138.jpg  438871.jpg\r\n",
      "1049459.jpg  167069.jpg   2271133.jpg  285147.jpg   3393547.jpg  43924.jpg\r\n",
      "1053665.jpg  1675632.jpg  227576.jpg   2855315.jpg  3393688.jpg  440188.jpg\r\n",
      "1068516.jpg  1678108.jpg  2283057.jpg  2856066.jpg  3396589.jpg  442757.jpg\r\n",
      "1068975.jpg  168006.jpg   2286639.jpg  2859933.jpg  339891.jpg\t 443210.jpg\r\n",
      "1081258.jpg  1682496.jpg  2287136.jpg  286219.jpg   3417789.jpg  444064.jpg\r\n",
      "1090122.jpg  1684438.jpg  2291292.jpg  2862562.jpg  3425047.jpg  444709.jpg\r\n",
      "1093966.jpg  168775.jpg   229323.jpg   2865730.jpg  3434983.jpg  447557.jpg\r\n",
      "1098844.jpg  1697339.jpg  2300534.jpg  2878151.jpg  3435358.jpg  461187.jpg\r\n",
      "1100074.jpg  1710569.jpg  2300845.jpg  2880035.jpg  3438319.jpg  461689.jpg\r\n",
      "1105280.jpg  1714605.jpg  231296.jpg   2881783.jpg  3444407.jpg  465494.jpg\r\n",
      "1117936.jpg  1724387.jpg  2315295.jpg  2884233.jpg  345734.jpg\t 468384.jpg\r\n",
      "1126126.jpg  1724717.jpg  2323132.jpg  2890573.jpg  3460673.jpg  477486.jpg\r\n",
      "114601.jpg   172936.jpg   2324994.jpg  2893832.jpg  3465327.jpg  482022.jpg\r\n",
      "1147047.jpg  1736543.jpg  2327701.jpg  2893892.jpg  3466159.jpg  482465.jpg\r\n",
      "1147883.jpg  1736968.jpg  2331076.jpg  2907177.jpg  3469024.jpg  483788.jpg\r\n",
      "1155665.jpg  1746626.jpg  233964.jpg   290850.jpg   3470083.jpg  493029.jpg\r\n",
      "1163977.jpg  1752330.jpg  2344227.jpg  2909031.jpg  3476564.jpg  503589.jpg\r\n",
      "1190233.jpg  1761285.jpg  234626.jpg   2910418.jpg  3478318.jpg  510757.jpg\r\n",
      "1208405.jpg  176508.jpg   234704.jpg   2912290.jpg  3488748.jpg  513129.jpg\r\n",
      "1209120.jpg  1772039.jpg  2357281.jpg  2916448.jpg  3492328.jpg  513842.jpg\r\n",
      "1212161.jpg  1777107.jpg  2361812.jpg  2916967.jpg  3518960.jpg  523535.jpg\r\n",
      "1213988.jpg  1787505.jpg  2365287.jpg  2927833.jpg  3522209.jpg  525041.jpg\r\n",
      "1219039.jpg  179293.jpg   2374582.jpg  2928643.jpg  3524429.jpg  534560.jpg\r\n",
      "1225762.jpg  1816235.jpg  239025.jpg   2929179.jpg  3528458.jpg  534633.jpg\r\n",
      "1230968.jpg  1822407.jpg  2390628.jpg  2936477.jpg  3531805.jpg  536535.jpg\r\n",
      "1236155.jpg  1823263.jpg  2392910.jpg  2938012.jpg  3536023.jpg  541410.jpg\r\n",
      "1241193.jpg  1826066.jpg  2394465.jpg  2938151.jpg  3538682.jpg  543691.jpg\r\n",
      "1248337.jpg  1828502.jpg  2395127.jpg  2939678.jpg  3540750.jpg  560503.jpg\r\n",
      "1257104.jpg  1828969.jpg  2396291.jpg  2940544.jpg  354329.jpg\t 561972.jpg\r\n",
      "126345.jpg   1829045.jpg  2400975.jpg  2940621.jpg  3547166.jpg  56240.jpg\r\n",
      "1264050.jpg  1829088.jpg  2403776.jpg  2949079.jpg  3553911.jpg  56409.jpg\r\n",
      "1264154.jpg  1836332.jpg  2403907.jpg  295491.jpg   3556871.jpg  564530.jpg\r\n",
      "1264858.jpg  1839025.jpg  240435.jpg   296268.jpg   355715.jpg\t 568972.jpg\r\n",
      "127029.jpg   1839481.jpg  2404695.jpg  2964732.jpg  356234.jpg\t 576725.jpg\r\n",
      "1289900.jpg  183995.jpg   2404884.jpg  2965021.jpg  3571963.jpg  588739.jpg\r\n",
      "1290362.jpg  184110.jpg   2407770.jpg  2966859.jpg  3576078.jpg  590142.jpg\r\n",
      "1295457.jpg  184226.jpg   2412263.jpg  2977966.jpg  3577618.jpg  60633.jpg\r\n",
      "1312841.jpg  1846706.jpg  2425062.jpg  2979061.jpg  3577732.jpg  60655.jpg\r\n",
      "1313316.jpg  1849364.jpg  2425389.jpg  2983260.jpg  3578934.jpg  606820.jpg\r\n",
      "1324791.jpg  1849463.jpg  2435316.jpg  2984311.jpg  358042.jpg\t 612551.jpg\r\n",
      "1327567.jpg  1849542.jpg  2437268.jpg  2988960.jpg  358045.jpg\t 614975.jpg\r\n",
      "1327667.jpg  1853564.jpg  2437843.jpg  2989882.jpg  3591821.jpg  616809.jpg\r\n",
      "1333055.jpg  1869467.jpg  2440131.jpg  2995169.jpg  359330.jpg\t 628628.jpg\r\n",
      "1334054.jpg  1870942.jpg  2443168.jpg  2996324.jpg  3601483.jpg  632427.jpg\r\n",
      "1335556.jpg  187303.jpg   2446660.jpg  3000131.jpg  3606642.jpg  636594.jpg\r\n",
      "1337814.jpg  187521.jpg   2455944.jpg  3002350.jpg  3609394.jpg  637374.jpg\r\n",
      "1340977.jpg  1888450.jpg  2458401.jpg  3007772.jpg  361067.jpg\t 640539.jpg\r\n",
      "1343209.jpg  1889336.jpg  2487306.jpg  3008192.jpg  3613455.jpg  644777.jpg\r\n",
      "134369.jpg   1907039.jpg  248841.jpg   3009617.jpg  3621464.jpg  644867.jpg\r\n",
      "1344105.jpg  1925230.jpg  2489716.jpg  3011642.jpg  3621562.jpg  658189.jpg\r\n",
      "134598.jpg   1927984.jpg  2490489.jpg  3020591.jpg  3621565.jpg  660900.jpg\r\n",
      "1346387.jpg  1930577.jpg  2495884.jpg  3030578.jpg  3623556.jpg  663014.jpg\r\n",
      "1348047.jpg  1937872.jpg  2495903.jpg  3047807.jpg  3640915.jpg  664545.jpg\r\n",
      "1351372.jpg  1941807.jpg  2499364.jpg  3059843.jpg  3643951.jpg  667075.jpg\r\n",
      "1362989.jpg  1942333.jpg  2500292.jpg  3074367.jpg  3653129.jpg  669180.jpg\r\n",
      "1367035.jpg  1945132.jpg  2509017.jpg  3082120.jpg  3656752.jpg  669960.jpg\r\n",
      "1371177.jpg  1961025.jpg  250978.jpg   3094354.jpg  3663518.jpg  6709.jpg\r\n",
      "1375640.jpg  1966300.jpg  2514432.jpg  3095301.jpg  3663800.jpg  674001.jpg\r\n",
      "1382427.jpg  1966967.jpg  2526838.jpg  3099645.jpg  3664376.jpg  676189.jpg\r\n",
      "1392718.jpg  1969596.jpg  252858.jpg   3100476.jpg  3670607.jpg  681609.jpg\r\n",
      "1395906.jpg  1971757.jpg  2532239.jpg  3110387.jpg  3671021.jpg  6926.jpg\r\n",
      "1400760.jpg  1976160.jpg  2534567.jpg  3113772.jpg  3671877.jpg  703556.jpg\r\n",
      "1403005.jpg  1984271.jpg  2535431.jpg  3116018.jpg  368073.jpg\t 703909.jpg\r\n",
      "1404770.jpg  1987213.jpg  2535456.jpg  3128952.jpg  368162.jpg\t 704316.jpg\r\n",
      "140832.jpg   1987639.jpg  2538000.jpg  3130412.jpg  368170.jpg\t 714298.jpg\r\n",
      "141056.jpg   1995118.jpg  2543081.jpg  3136.jpg     3693649.jpg  720060.jpg\r\n",
      "141135.jpg   1995252.jpg  2544643.jpg  313851.jpg   3700079.jpg  726083.jpg\r\n",
      "1413972.jpg  199754.jpg   2547797.jpg  3140083.jpg  3704103.jpg  728020.jpg\r\n",
      "1421393.jpg  2002400.jpg  2548974.jpg  3140147.jpg  3707493.jpg  732986.jpg\r\n",
      "1428947.jpg  2011264.jpg  2549316.jpg  3142045.jpg  3716881.jpg  734445.jpg\r\n",
      "1433912.jpg  2012996.jpg  2561199.jpg  3142618.jpg  3724677.jpg  735441.jpg\r\n",
      "143490.jpg   2013535.jpg  2563233.jpg  3142674.jpg  3727036.jpg  740090.jpg\r\n",
      "1445352.jpg  2017387.jpg  256592.jpg   3143192.jpg  3727491.jpg  745189.jpg\r\n",
      "1446401.jpg  2018173.jpg  2568848.jpg  314359.jpg   3736065.jpg  752203.jpg\r\n",
      "1453991.jpg  2020613.jpg  2573392.jpg  3157832.jpg  37384.jpg\t 75537.jpg\r\n",
      "1456841.jpg  2032669.jpg  2592401.jpg  3159818.jpg  3743286.jpg  756655.jpg\r\n",
      "146833.jpg   203450.jpg   2599817.jpg  3162376.jpg  3745515.jpg  762210.jpg\r\n",
      "1476404.jpg  2034628.jpg  2603058.jpg  3168620.jpg  3750472.jpg  763690.jpg\r\n",
      "1485083.jpg  2036920.jpg  2606444.jpg  3171085.jpg  3752362.jpg  767442.jpg\r\n",
      "1487113.jpg  2038418.jpg  2614189.jpg  317206.jpg   3766099.jpg  786409.jpg\r\n",
      "148916.jpg   2042975.jpg  2614649.jpg  3173444.jpg  3770370.jpg  80215.jpg\r\n",
      "149087.jpg   2045647.jpg  2615718.jpg  3180182.jpg  377190.jpg\t 802348.jpg\r\n",
      "1493169.jpg  2050584.jpg  2619625.jpg  31881.jpg    3777020.jpg  804684.jpg\r\n",
      "149682.jpg   2052542.jpg  2622140.jpg  3191589.jpg  3777482.jpg  812163.jpg\r\n",
      "1508094.jpg  2056627.jpg  262321.jpg   3204977.jpg  3781152.jpg  813486.jpg\r\n",
      "1512226.jpg  2062248.jpg  2625330.jpg  320658.jpg   3787809.jpg  819027.jpg\r\n",
      "1512347.jpg  2081995.jpg  2628106.jpg  3209173.jpg  3788729.jpg  822550.jpg\r\n",
      "1524526.jpg  2087958.jpg  2629750.jpg  3223400.jpg  3790962.jpg  823766.jpg\r\n",
      "1530833.jpg  2088030.jpg  2643906.jpg  3223601.jpg  3792514.jpg  827764.jpg\r\n",
      "1539499.jpg  2088195.jpg  2644457.jpg  3241894.jpg  379737.jpg\t 830007.jpg\r\n",
      "1541672.jpg  2090493.jpg  2648423.jpg  3245533.jpg  3807440.jpg  838344.jpg\r\n",
      "1548239.jpg  2090504.jpg  2651300.jpg  3245622.jpg  381162.jpg\t 853327.jpg\r\n",
      "1550997.jpg  2125877.jpg  2653594.jpg  3247009.jpg  3812039.jpg  854150.jpg\r\n",
      "1552530.jpg  2129685.jpg  2661577.jpg  3253588.jpg  3829392.jpg  864997.jpg\r\n",
      "15580.jpg    2133717.jpg  2668916.jpg  3260624.jpg  3830872.jpg  885571.jpg\r\n",
      "1559052.jpg  2136662.jpg  268444.jpg   326587.jpg   38442.jpg\t 907107.jpg\r\n",
      "1563266.jpg  213765.jpg   2691461.jpg  32693.jpg    3855584.jpg  908261.jpg\r\n",
      "1567554.jpg  2138335.jpg  2706403.jpg  3271253.jpg  3857508.jpg  910672.jpg\r\n",
      "1575322.jpg  2140776.jpg  270687.jpg   3274423.jpg  386335.jpg\t 911803.jpg\r\n",
      "1588879.jpg  214320.jpg   2707522.jpg  3280453.jpg  3867460.jpg  91432.jpg\r\n",
      "1594719.jpg  2146963.jpg  2711806.jpg  3298495.jpg  3868959.jpg  914570.jpg\r\n",
      "1595869.jpg  215222.jpg   2716993.jpg  330182.jpg   3869679.jpg  922752.jpg\r\n",
      "1598345.jpg  2154126.jpg  2724554.jpg  3306627.jpg  388776.jpg\t 923772.jpg\r\n",
      "1598885.jpg  2154779.jpg  2738227.jpg  3315727.jpg  3890465.jpg  926414.jpg\r\n",
      "1600179.jpg  2159975.jpg  2748917.jpg  331860.jpg   3894222.jpg  931356.jpg\r\n",
      "1600794.jpg  2163079.jpg  2760475.jpg  332232.jpg   3895825.jpg  937133.jpg\r\n",
      "160552.jpg   217250.jpg   2761427.jpg  3322909.jpg  389739.jpg\t 945791.jpg\r\n",
      "1606596.jpg  2172600.jpg  2765887.jpg  332557.jpg   3916407.jpg  947877.jpg\r\n",
      "1615395.jpg  2173084.jpg  2768451.jpg  3326734.jpg  393349.jpg\t 952407.jpg\r\n",
      "1618011.jpg  217996.jpg   2771149.jpg  3330642.jpg  393494.jpg\t 952437.jpg\r\n",
      "1619357.jpg  2193684.jpg  2779040.jpg  3333128.jpg  398288.jpg\t 955466.jpg\r\n",
      "1621763.jpg  220341.jpg   2788312.jpg  3333735.jpg  40094.jpg\t 9555.jpg\r\n",
      "1623325.jpg  22080.jpg\t  2788759.jpg  3334973.jpg  401094.jpg\t 961341.jpg\r\n",
      "1624450.jpg  2216146.jpg  2796102.jpg  3335013.jpg  401144.jpg\t 97656.jpg\r\n",
      "1624747.jpg  2222018.jpg  280284.jpg   3335267.jpg  401651.jpg\t 979110.jpg\r\n",
      "1628861.jpg  2223787.jpg  2807888.jpg  3346787.jpg  405173.jpg\t 980247.jpg\r\n",
      "1632774.jpg  2230959.jpg  2815172.jpg  3364420.jpg  405794.jpg\t 982988.jpg\r\n",
      "1636831.jpg  2232310.jpg  2818805.jpg  336637.jpg   40762.jpg\t 987732.jpg\r\n",
      "1645470.jpg  2233395.jpg  2823872.jpg  3372616.jpg  413325.jpg\t 996684.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls pizza_steak/train/steak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fvd6YeUsEchu",
    "outputId": "24c883fb-8daf-444b-f8bc-61a60ae38af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in 'pizza_steak' .\n",
      "There are 2 directories and 0 images in 'pizza_steak/test' .\n",
      "There are 0 directories and 250 images in 'pizza_steak/test/steak' .\n",
      "There are 0 directories and 250 images in 'pizza_steak/test/pizza' .\n",
      "There are 2 directories and 0 images in 'pizza_steak/train' .\n",
      "There are 0 directories and 750 images in 'pizza_steak/train/steak' .\n",
      "There are 0 directories and 750 images in 'pizza_steak/train/pizza' .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Walk through pizza_steak directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}' .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9jjD1RhGvVC",
    "outputId": "e2fc0631-ded4-402b-a77a-39883962846d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x. 1 saikalyansathish saikalyansathish  18 Feb 26 23:37 .\r\n",
      "drwxr-xr-x. 1 saikalyansathish saikalyansathish 162 Feb 26 23:37 ..\r\n",
      "drwxr-xr-x. 1 saikalyansathish saikalyansathish  20 Feb 26 23:37 test\r\n",
      "drwxr-xr-x. 1 saikalyansathish saikalyansathish  20 Feb 26 23:37 train\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la pizza_steak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adQHgU3nIgtH"
   },
   "source": [
    "Okay surprisingly i didnt find any .DS_Store file which daniel showed but still no problem we will proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAInh5L5IORl",
    "outputId": "1179bbb3-77fa-40bb-943e-0640e906541d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another way to find out how many images are in a file\n",
    "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
    "num_steak_images_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr8BfaKlL34l"
   },
   "source": [
    "To visualize our images, first let's get the clas names programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ua6mwxpbLUy-",
    "outputId": "981bd12e-b2a4-4789-ddf6-84ea5378bce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pizza' 'steak']\n"
     ]
    }
   ],
   "source": [
    "# Get the classnames programmatically\n",
    "import pathlib\n",
    "import numpy as np\n",
    "data_dir = pathlib.Path(\"pizza_steak/train\")\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) #Created a list of class_names from the subdirectories\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tzobaFIWN6l3"
   },
   "outputs": [],
   "source": [
    "# Let's visualize our images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def view_random_image(target_dir, target_class):\n",
    "  #Setup the target directory (we'll view images from here)\n",
    "  target_folder = target_dir+target_class\n",
    "\n",
    "  #Get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "  print(random_image)\n",
    "\n",
    "  # Read in the image and plot it using matplotlib\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class)\n",
    "  plt.axis(\"off\");\n",
    "\n",
    "  print(f\"Image shape: {img.shape}\") #show the shape of the image\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "KaM0J459nUE0",
    "outputId": "284be1cb-9eaa-4675-ad79-ee2cdd58185c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# view a random image from the training dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m view_random_image(target_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpizza_steak/train/\u001b[39m\u001b[38;5;124m\"\u001b[39m,target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpizza\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mview_random_image\u001b[0;34m(target_dir, target_class)\u001b[0m\n\u001b[1;32m      8\u001b[0m target_folder \u001b[38;5;241m=\u001b[39m target_dir\u001b[38;5;241m+\u001b[39mtarget_class\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#Get a random image path\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m random_image \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(os\u001b[38;5;241m.\u001b[39mlistdir(target_folder), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(random_image)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Read in the image and plot it using matplotlib\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# view a random image from the training dataset\n",
    "img = view_random_image(target_dir=\"pizza_steak/train/\",target_class=\"pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HDRSIDtxHGO"
   },
   "source": [
    "Initially when we return img it returns and inputs as an array so below we convert it to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp8W4tqjsqYU",
    "outputId": "5687be92-b7a5-4558-bbbd-b2e0ca0a9f11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 23:37:41.865935: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.866159: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.866307: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.866584: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.866709: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.866809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.866945: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.867064: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-26 23:37:41.867138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2296 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(289, 512, 3), dtype=uint8, numpy=\n",
       "array([[[54, 51, 32],\n",
       "        [57, 54, 35],\n",
       "        [59, 56, 37],\n",
       "        ...,\n",
       "        [27, 17, 15],\n",
       "        [32, 22, 20],\n",
       "        [34, 24, 22]],\n",
       "\n",
       "       [[59, 56, 37],\n",
       "        [61, 58, 39],\n",
       "        [62, 59, 40],\n",
       "        ...,\n",
       "        [20, 12,  9],\n",
       "        [23, 15, 12],\n",
       "        [25, 17, 14]],\n",
       "\n",
       "       [[58, 55, 36],\n",
       "        [59, 56, 37],\n",
       "        [61, 58, 39],\n",
       "        ...,\n",
       "        [11,  8,  3],\n",
       "        [13, 10,  5],\n",
       "        [14, 11,  6]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6,  5,  3],\n",
       "        [ 6,  2,  1],\n",
       "        [ 6,  2,  0],\n",
       "        ...,\n",
       "        [95, 65, 31],\n",
       "        [94, 64, 30],\n",
       "        [92, 63, 29]],\n",
       "\n",
       "       [[ 8,  4,  3],\n",
       "        [ 6,  2,  1],\n",
       "        [ 6,  2,  1],\n",
       "        ...,\n",
       "        [98, 68, 34],\n",
       "        [92, 63, 29],\n",
       "        [89, 60, 26]],\n",
       "\n",
       "       [[ 5,  5,  3],\n",
       "        [ 4,  4,  2],\n",
       "        [ 3,  3,  1],\n",
       "        ...,\n",
       "        [98, 69, 37],\n",
       "        [99, 72, 42],\n",
       "        [86, 59, 29]]], dtype=uint8)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.constant(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfMh3YaDvdUl",
    "outputId": "8f65eebc-bd0f-4555-8a36-485f8facac6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 512, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the image shape\n",
    "img.shape # returns width, height, colour channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WITd1EM0wGTv",
    "outputId": "d172cb84-9502-48f7-d0b5-b6e57871bf98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.21176471, 0.2       , 0.1254902 ],\n",
       "        [0.22352941, 0.21176471, 0.1372549 ],\n",
       "        [0.23137255, 0.21960784, 0.14509804],\n",
       "        ...,\n",
       "        [0.10588235, 0.06666667, 0.05882353],\n",
       "        [0.1254902 , 0.08627451, 0.07843137],\n",
       "        [0.13333333, 0.09411765, 0.08627451]],\n",
       "\n",
       "       [[0.23137255, 0.21960784, 0.14509804],\n",
       "        [0.23921569, 0.22745098, 0.15294118],\n",
       "        [0.24313725, 0.23137255, 0.15686275],\n",
       "        ...,\n",
       "        [0.07843137, 0.04705882, 0.03529412],\n",
       "        [0.09019608, 0.05882353, 0.04705882],\n",
       "        [0.09803922, 0.06666667, 0.05490196]],\n",
       "\n",
       "       [[0.22745098, 0.21568627, 0.14117647],\n",
       "        [0.23137255, 0.21960784, 0.14509804],\n",
       "        [0.23921569, 0.22745098, 0.15294118],\n",
       "        ...,\n",
       "        [0.04313725, 0.03137255, 0.01176471],\n",
       "        [0.05098039, 0.03921569, 0.01960784],\n",
       "        [0.05490196, 0.04313725, 0.02352941]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.02352941, 0.01960784, 0.01176471],\n",
       "        [0.02352941, 0.00784314, 0.00392157],\n",
       "        [0.02352941, 0.00784314, 0.        ],\n",
       "        ...,\n",
       "        [0.37254902, 0.25490196, 0.12156863],\n",
       "        [0.36862745, 0.25098039, 0.11764706],\n",
       "        [0.36078431, 0.24705882, 0.11372549]],\n",
       "\n",
       "       [[0.03137255, 0.01568627, 0.01176471],\n",
       "        [0.02352941, 0.00784314, 0.00392157],\n",
       "        [0.02352941, 0.00784314, 0.00392157],\n",
       "        ...,\n",
       "        [0.38431373, 0.26666667, 0.13333333],\n",
       "        [0.36078431, 0.24705882, 0.11372549],\n",
       "        [0.34901961, 0.23529412, 0.10196078]],\n",
       "\n",
       "       [[0.01960784, 0.01960784, 0.01176471],\n",
       "        [0.01568627, 0.01568627, 0.00784314],\n",
       "        [0.01176471, 0.01176471, 0.00392157],\n",
       "        ...,\n",
       "        [0.38431373, 0.27058824, 0.14509804],\n",
       "        [0.38823529, 0.28235294, 0.16470588],\n",
       "        [0.3372549 , 0.23137255, 0.11372549]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the pixel values between 0 and 1\n",
    "img/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9JVrblWS1Lk"
   },
   "source": [
    "As we've discussed before, many machine learning models, including neural networks prefer the values they work with to be between 0 and 1. Knowing this, one of the most common preprocessing steps for working with images is to scale(also referred to as normalize) their pixel values by dividing the image arrays by 255.(since 255 is the maximum pixel value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "23Ppbtfgwpm0"
   },
   "outputs": [],
   "source": [
    "#An end-to-end example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EKWmq8STtsn"
   },
   "source": [
    "lets build a convolutional neural network to find patterns in our images, more specifically we need a way to:\n",
    "\n",
    "* Load our images\n",
    "* Preprocess our images\n",
    "* Build a CNN to find patterns in our images\n",
    "* Compile our CNN\n",
    "* Fit the CNN to our training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bttyQL0sVlDd",
    "outputId": "369708df-ce06-48f5-e278-94986f3863e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 22:26:18.753091: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.753334: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.753440: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.753659: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.753766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.753864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.753999: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.754100: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:26:18.754213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2435 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 22:26:20.167379: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-01 22:26:20.540578: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-01 22:26:22.416321: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-01 22:26:22.867914: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f75c16136d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-01 22:26:22.867944: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2024-03-01 22:26:22.872168: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709312182.954262   40633 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 19s 352ms/step - loss: 0.5807 - accuracy: 0.7360 - val_loss: 0.8059 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.5694 - accuracy: 0.7500 - val_loss: 0.8571 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 0.5636 - accuracy: 0.7500 - val_loss: 0.8706 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.5637 - accuracy: 0.7500 - val_loss: 0.7317 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.5612 - accuracy: 0.7500 - val_loss: 0.8190 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Preprocess data (get all of the pixel values between 0 and1 , also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Setup paths to our data directories\n",
    "train_dir = \"/home/saikalyansathish/Desktop/pizza_steak\"\n",
    "test_dir = \"/home/saikalyansathish/Desktop/pizza_steak/test\"\n",
    "\n",
    "#Import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(directory = train_dir, batch_size=64, target_size=(224, 224), class_mode=\"binary\", seed=42)\n",
    "valid_data = valid_datagen.flow_from_directory(directory = test_dir,batch_size=64, target_size=(224, 224), class_mode=\"binary\", seed=42)\n",
    "\n",
    "#Build a CNN model (same as the Tiny VGG on the CNN-explainer website)\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           activation=\"relu\",\n",
    "                           input_shape=(224,224,3)),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2,padding=\"valid\"),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "])\n",
    "# Compile our CNN\n",
    "model_1.compile(loss=\"binary_crossentropy\",optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_1 = model_1.fit(train_data, epochs=5, steps_per_epoch=len(train_data), validation_data=valid_data, validation_steps=len(valid_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HONrseG-oVKN",
    "outputId": "0ec7b90e-1990-46ba-d978-4d9dd902a1dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) # 1500/32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fKk5Rv7rGEn"
   },
   "source": [
    "if the above cell is taking longer than 10seconds per epoch, make sure you're using a gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTIdhHsarXo5",
    "outputId": "b8c8860d-d327-48e9-fb0d-e07bca7e0c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 10)      280       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 220, 220, 10)      910       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 110, 110, 10)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 108, 108, 10)      910       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 106, 106, 10)      910       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 53, 53, 10)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28090)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 28091     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31101 (121.49 KB)\n",
      "Trainable params: 31101 (121.49 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Get a model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_XP8WNj2kd4",
    "outputId": "a11c7527-314a-4479-a2bb-b36c2f63afe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.image.DirectoryIterator at 0x7f7835b75150>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlEPvBjF0soZ"
   },
   "source": [
    "Using the same model as before for different dataset\n",
    "\n",
    "Lets replicate the model we've built in a previous section to see if it works with our image data.\n",
    "\n",
    "The model we're building is from the tensorflow playground:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hhGAMVyEsIY5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 0.7721 - accuracy: 0.7325 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 0.6835 - accuracy: 0.7500 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 0.6762 - accuracy: 0.7500 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 0.6693 - accuracy: 0.7500 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 0.6627 - accuracy: 0.7500 - val_loss: 0.6958 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Create a model to replicate the Tensorflow playground model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "#Compile the model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "#Fit the model\n",
    "history_2 = model_2.fit(train_data,\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=valid_data,\n",
    "                        validation_steps=len(valid_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /physical_device:GPU:0\n",
      "Model: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 22:28:23.837018: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:28:23.837286: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:28:23.837394: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:28:23.837531: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:28:23.837635: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-01 22:28:23.837711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 2435 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the list of physical devices\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices:\n",
    "    # Print information about each GPU\n",
    "    for gpu in physical_devices:\n",
    "        print(\"GPU:\", gpu.name)\n",
    "        device_details = tf.test.gpu_device_name()\n",
    "        print(\"Model:\", device_details)\n",
    "else:\n",
    "    print(\"No GPU available. TensorFlow is using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 150528)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 602116    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 602141 (2.30 MB)\n",
      "Trainable params: 602141 (2.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 9s 240ms/step - loss: 5.4772 - accuracy: 0.6450 - val_loss: 4.1919 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 1.3931 - accuracy: 0.6205 - val_loss: 1.3094 - val_accuracy: 0.4780\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 8s 252ms/step - loss: 1.1136 - accuracy: 0.6270 - val_loss: 2.7605 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.8901 - accuracy: 0.6695 - val_loss: 1.4016 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 0.7190 - accuracy: 0.6815 - val_loss: 0.8653 - val_accuracy: 0.3660\n"
     ]
    }
   ],
   "source": [
    "# DEspite having 20x more parameters than our CNN (model_1), model_2 performs terribly... let's try to improve it.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Create the model (same as above but let's step it up a notch)\n",
    "model_3 = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    \n",
    "   \n",
    "])\n",
    "\n",
    "#compile the model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=tf.keras.optimizers.Adam(),\n",
    "                 metrics=[\"accuracy\"])\n",
    "#Fit the model\n",
    "history_3 = model_3.fit(train_data,\n",
    "                       epochs=5,\n",
    "                       steps_per_epoch=len(train_data),\n",
    "                       validation_data=valid_data,\n",
    "                       validation_steps=len(valid_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
